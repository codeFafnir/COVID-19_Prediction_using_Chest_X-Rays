{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of COVID-19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLONkkFqlA13"
      },
      "source": [
        "!wget https://cb.lk/covid_19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpqlca56kJf3"
      },
      "source": [
        "!unzip covid_19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vH9LmdZlu_M"
      },
      "source": [
        "train_path = \"CovidDataset/Train\"\n",
        "val_path = \"CovidDataset/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb3fwElEmIi_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV_s0O2OmXeH"
      },
      "source": [
        "#We are building a sequential layers\n",
        "#The input shape is (224,224) as it is somewhat standard and ImageNet models \n",
        "#and a few other models are trained in this size, it is not too big, not too small\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\n",
        "model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
        "#Adding two (3,3) layers instead of one (5,5) layer would increase the non linearity which \n",
        "#would eventually increase the ability of the network to learn complex functions\n",
        "#another benefit is we have lesser number of parameters in two stacked (3,3) layers instead \n",
        "#of a single (5,5) layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256,kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0aUedBbqV_W",
        "outputId": "4e23bbb6-1007-47e5-d680-aa3d092f6221"
      },
      "source": [
        "model.summary()\n",
        "#As we are go deeper into the network we need to increase the number of channels\n",
        "#as we go deeper into the network we see more complex features, so increasing the \n",
        "#number of channels increases the number of features recognised, since deeper in the network\n",
        "#we have an increased receptive field.\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 220, 220, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 108, 108, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 52, 52, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36864)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                2359360   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,784,769\n",
            "Trainable params: 2,784,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKNpPTB3qjvH"
      },
      "source": [
        "#training phase\n",
        "#We here are scaling the image, then are introducing some augmentation\n",
        "#where we have a shear range of some random crops of the image\n",
        "#and some random zooms of the image too.\n",
        "#we also include horizontal flipping of the image\n",
        "# We do not do vertical flipping of the image because our X-rays have \n",
        "# Postereoanterior view in which we cannot flip our images.\n",
        "train_datagen = image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        ") \n",
        "#We can have class_mode to categorical when we have multi class classification\n",
        "test_datagen = image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4-zzDtutEcx",
        "outputId": "302c286d-9a0e-4bce-ee83-4eaa58af3989"
      },
      "source": [
        "train_datagen = train_datagen.flow_from_directory(\n",
        "    'CovidDataset/Train',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 224 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmIaSbMXtFZf",
        "outputId": "dc011074-c3db-4def-ce42-13fbd0d48f3d"
      },
      "source": [
        "train_datagen.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtOO8USVtPom",
        "outputId": "573b88ae-b691-4f8e-be38-afcabd2d5a15"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'CovidDataset/Val',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ke7hy-ZuNzT",
        "outputId": "1473c5b3-154c-4fa7-d7ef-dc3ad08812da"
      },
      "source": [
        "hst = model.fit_generator(\n",
        "    train_datagen,\n",
        "    steps_per_epoch=4,\n",
        "    epochs=10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.5194 - accuracy: 0.7734 - val_loss: 0.5520 - val_accuracy: 0.7167\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4228 - accuracy: 0.8125 - val_loss: 0.4447 - val_accuracy: 0.7667\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4485 - accuracy: 0.7891 - val_loss: 0.3321 - val_accuracy: 0.9500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3789 - accuracy: 0.8594 - val_loss: 0.3090 - val_accuracy: 0.9000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2679 - accuracy: 0.8672 - val_loss: 0.2050 - val_accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1971 - accuracy: 0.9297 - val_loss: 0.1798 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2894 - accuracy: 0.9141 - val_loss: 0.1665 - val_accuracy: 0.9833\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1513 - accuracy: 0.9453 - val_loss: 0.0628 - val_accuracy: 0.9833\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1528 - accuracy: 0.9453 - val_loss: 0.0798 - val_accuracy: 0.9833\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1822 - accuracy: 0.9375 - val_loss: 0.0786 - val_accuracy: 0.9833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4WWsoP-uwW2"
      },
      "source": [
        "# Class activation mappings\n",
        "# Grad CAM technique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnLtAOoM6NN6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f1m4ojT6bvI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}